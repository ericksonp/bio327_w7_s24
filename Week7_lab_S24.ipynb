{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff7cde71",
   "metadata": {},
   "source": [
    "# Biology 327 Lab: Week 7 (spring 2024)\n",
    "\n",
    "## Processing sequencing reads and mapping to a reference genome\n",
    "\n",
    "Remember these pro-tips:\n",
    "- triple-click on a line to highlight the entire line to copy\n",
    "- set up a split screen to put this notebook next to your terminal window\n",
    "\n",
    "**New pro-tip for today:** you can use the up arrow to re-enter the last line of code that you ran. So if you forgot a character or had a different typo, just hit the up arrow and make the fix rather than retyping the whole thing!\n",
    "\n",
    "## 0. Logging on to spydur:\n",
    "\n",
    "First let's log into `spydur`. Update the code below with your netid and use it to log in by copying into terminal. If your key setup worked last week, you should not need to enter a password, but if you are prompted, enter your netid password (it won't show up as typing anything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh YOURNETID@spydur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0db06f",
   "metadata": {},
   "source": [
    "## 1. Setting up folders\n",
    "Now let's make new folders to work in for this week's lab. After last week, you should have a personal folder in the `~/shared_perickso/` directory on Spydur. (remember that `~` is a shortcut to `/home/YOURNETID`\n",
    "\n",
    "Navigate to your personal folder now.\n",
    "\n",
    "Use `mkdir` to make a subfolder called `Lab7`. \n",
    "\n",
    "change directories to your new `Lab7` folder.\n",
    "\n",
    "In the end you should have a folder at `/home/YOURNETID/shared_perickso/YOURFIRSTNAME/Lab7` and be in that folder (replacing your netid and first name)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9e0828",
   "metadata": {},
   "source": [
    "## 2. Introducting variables in Unix\n",
    "\n",
    "Just like we can save different object as variable names in R, we can also save text, numbers, and files to variable names in UNIX. The advantage of doing this is that it can save you a lot of typing, and in some cases make complex operations much simpler. The formula is `variable_name=variable_value`. We can then refer back to those variables by typing `${variable_name}`. \n",
    "\n",
    "You could make a variable with your name like this: try running the code below in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de63e1c-12e9-43b2-a318-0af421b04bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=Darwin\n",
    "echo \"${name} is my favorite scientist!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02ea2b-f95e-4edf-bd1c-260cd9069601",
   "metadata": {},
   "source": [
    "If you changed \"Darwin\" to something else like \"Marie-Claire King\", it would instead print whatever word you had saved in the sentence. This seems trivial now but will become a useful skill as we start to build more complex code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafbd53",
   "metadata": {},
   "source": [
    "## 3. Set up an interactive job\n",
    "My lab (the Erickson lab) \"owns\" one computer that is part of the network of computers that makes up the **Spydur** computing cluster. We will be running our jobs on that computer.  To ensure that everyone's jobs are able to run, we will tell the computer how many cores of computing power and how much memory we need. Copy the code below and run it in terminal exactly as-is so that all your future commands run on my branch of `spydur`. This will give us each 20GB of memory on 3 computing cores to run our current operations for the next 3 hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3880ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "srun --pty -t 3:00:00 --mem=20G --partition erickson --ntasks-per-node=3 bash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c7e00",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Make a variable to save our working directory\n",
    "\n",
    "Now we'll save the name of the Lab7 folder as our \"working directory\". The working directory is where you have files and run code for the current analysis. We will save the directory as a variable name.  That way, we can just type `${WD}` instead of the full directory for everything we want to do. Update the code below with with the path to your Lab7 folder and run it. It should print back the location of `${WD}`. Anytime you want to use a path to your current working directory, you can type `${WD}` insteads of `/home/YOURNETID/shared_perickso/YOURFIRSTNAME/Lab7`. See how much typing that will save you? Enter your WD below, then use `echo ${WD}` to confirm that it saved correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656531d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#provide path to your working directory after WD= below\n",
    "WD=\n",
    "echo ${WD}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ce1471-0fab-44c8-a14a-1231880b9051",
   "metadata": {},
   "source": [
    "Now use a command from last week to change directories to your new working directory, **using the shortcut variable** you just made above. Enter the code below and then copy and paste it to run in terminal. Then confirm you are working in the correct directory with a different command from last week. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab830ac-071e-4f93-9f3f-62e01857b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0de9856",
   "metadata": {},
   "source": [
    "## 5. Finding the right files\n",
    "We left off last week after looking at FastQ and FastA files.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc83106-a364-47e5-b83b-b63f19da1a50",
   "metadata": {},
   "source": [
    "**Question: What is the difference between the two file types?  What information is stored in each?**\n",
    "\n",
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c455c1c6-bf7b-4d1e-ad2f-b45c7e876d0d",
   "metadata": {},
   "source": [
    "This week, we are going to take some of our sequencing reads from fastq files and learn how to process them and map them to a reference genome in a fasta file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06ff55e-b754-48ad-a538-d6511ce16765",
   "metadata": {
    "tags": []
   },
   "source": [
    "Use the command below to look at the file in `shared_perickso` named `samples.txt`. The`-S` after the `less` will make the columns display in a more orderly fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be79cc-392e-4ed8-81b7-3682d95f9265",
   "metadata": {},
   "outputs": [],
   "source": [
    "less -S ~/shared_perickso/samples.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9960325e-f09e-4dde-8ace-b9293d72c4f0",
   "metadata": {},
   "source": [
    "This file contains all of the information about all of the _Z. indianus_ pooled sequencing libraries my lab has sequenced, sorted by the collection date. Here is the metadata for that file: \n",
    "- Pool: The name of the sequencing library. \n",
    "- Location: The location flies were collected:\n",
    "    - CM = Carter Mountain, Charlottesville, VA\n",
    "    - MIA = University of Miami, FL\n",
    "    - FL = Fruit and Spice Park, Miami, FL\n",
    "    - BGFL = Botantical Garden, Miami, FL\n",
    "    - HPO = Hanover Peach Orchard, Richmond, VA\n",
    "    - HCGA = Hillcrest Orchard, Ellijay, GA\n",
    "    - CK = Cross Keys Orchard, Harrisonburg, VA\n",
    "    - MA = Acton, MA (flies combined from multiple orchards)\n",
    "    - CT = Lyman Orchards, Middleton, CT\n",
    "    - PA = Linvilla Orchards, Media, PA\n",
    "    - CH = Chiles Orchards, Crozet, VA\n",
    "- Year: The year of sampling\n",
    "- Sample Date: The day flies were collected\n",
    "- females: The number of female flies in the pool\n",
    "- males: The number of male flies in the pool\n",
    "- total: The total number of flies in the pool **this is the final number in the row and is important for a question below**\n",
    "\n",
    "Note that the columns don't display super nicely so the last three numbers are females, males, and total, regardless of how they are shifted on the page. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471df8ef-b225-4c99-8386-1adee103fdd0",
   "metadata": {},
   "source": [
    "**Question: What are the names of the two samples that you and your partner will be comparing? The name should be \"ZP_\" followed by a number**\n",
    "\n",
    "**Answer here**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa6c87-2862-4c55-9f52-ac376e99e96d",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Question: How many flies were squished up and pooled together for each of your samples?**\n",
    "\n",
    "**Answer here**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9c60a0-b271-459b-b684-3be3c995b635",
   "metadata": {},
   "source": [
    "**Question: How might the number of flies in the sample affect the accuracy of our allele frequency estimates? (which is generally more accurate, larger samples or smaller samples?)**\n",
    "\n",
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fc6f06-3c4a-4f57-8577-182930631765",
   "metadata": {},
   "source": [
    "**(Challenge!) Question: When sequencing is performed, you typically load a fixed amount of DNA onto the flow cell. Given that information, will the number of flies in the sample affect how many sequencing reads you get? Why or why not?**\n",
    "\n",
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38397935-1aab-4ce1-9117-c9dbdb1f8856",
   "metadata": {},
   "source": [
    "Each partner will process one of your two samples for steps 6-10. Decide now with your partner who is going to process which sample.\n",
    " \n",
    "**Question: which of your two samples will you be working with going forward?**\n",
    "\n",
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a9a0b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Looking at the real fastq files\n",
    "\n",
    "Our fastq files have a lot of data in them: remember that we calculated last week that we need approximately 100,000,000 sequencing reads to sequence the genome 100 times to estimate allele frequencies!. The raw data are stored in a compressed form, indicated by a `.gz` at the end of the file.\n",
    "\n",
    "Change directories to `/shared_perickso/fastq`. Then change directories to the folder for your sample. Use `ls -lh`  (those are both lower-case letter Ls) to see the names and sizes of your samples. G=gigabytes, M=megabytes, K=kilobytes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d724eb2-4ab6-45d3-9a43-dc7a660a0da3",
   "metadata": {},
   "source": [
    "**Question: How big are the raw data files for your samples?**\n",
    "\n",
    "**Answer here**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3028d9e5-73b9-46b4-a576-15e79f2a73ee",
   "metadata": {},
   "source": [
    "One of these compressed files might be bigger than your monthly cell phone data usage (the amount of data in all the videos and music you stream), which means they can take a long time to process. I ran a program that randomly downsampled the fastq files so that only 0.5% of sequencing the reads were retained. In other words, it kept one in every 200 of the original sequence reads from the machine. It was run equally on both the read_1 and read_2 files so that the same pairs of reads were retained in each file. So, we have 0.5% of the paired-end reads from the original sample to work with. These reads are saved in `/shared_perickso/dfastq` (the \"d\" is for \"downsampled\"). Make sure you use this folder or your next steps will take a very long time to run!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820871db-903b-41d2-b9e7-7f3ab084de6f",
   "metadata": {},
   "source": [
    "**Question: Navigate to `shared_perickso/dfastq` which contains the smaller files. Use a command from last week (or your cheat sheet to determine how many lines are in the \"downsampled\" files for your sample (make sure to run it on both the read_1 and read_2 files) and report those numbers** \n",
    "\n",
    "**Answer read 1**\n",
    "\n",
    "**Answer read 2**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d725da3-ba30-4fd3-a442-d589f97d861e",
   "metadata": {},
   "source": [
    "**Question: Given how sequences are represented in a `fastq` file, how many unique sequences does each fastq file have? (hint: remember that it takes more than one line to store the sequencing information**\n",
    "\n",
    "**Answer here** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec96cbd-3f0f-488d-af53-5412d2db7bf3",
   "metadata": {},
   "source": [
    "**Question: If each file contains only one in every 200 reads from the starting file, how many total reads did you have? (count both read 1 and read 2!) How does that compare to the approximate number of reads you calculated last week? ** \n",
    "\n",
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aad4e1-43a8-4fba-a055-57ed838f5f45",
   "metadata": {},
   "source": [
    "## 7. Merging reads\n",
    "\n",
    "Recall that we are using 150 bp, paired-end reads, which are sequenced from both ends of the same molecule.\n",
    "\n",
    "**Question: Why might paired end reads occasionally have overlapping sequence? What would have to be true about the molecule of DNA that was sequenced for this to happen?**\n",
    "\n",
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d173dc5-5f3d-4d07-a1d2-565402bb2ca8",
   "metadata": {},
   "source": [
    "Because some reads might overlap, the sequence in the overlapping part represents duplicated data that is not a unique sequence. Therefore, we wouldn't want to count both of the overlapping reads as separate counts when we calculate our allele frequencies because we'd be double counting some information from the same molecule. We need to get rid of this duplication by merging the reads together. Essentially, the computer finds the overlap, if it exists, and comibines the two shorter overlapping reads into one long read that can then be aligned to the genome. So if you had read 1 as `ACTGGGGA` and read 2 was `GGGGATCTCA` the computer would combine the overlapping `GGGGA` to make a single read of `ACTGGGGATCTCA`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0ee609",
   "metadata": {},
   "source": [
    "The software that we are going to use to merge our reads is called `bbmap`. The specific program we are using is called `merge.sh`. The program takes two input files, the `read_1` and `read_2` fastq files. It finds any occasions where the two reads overlap, and merges them into a single read. The merged reads get saved into a new file. The reads that don't overlap remain the same. \n",
    "\n",
    "It has two input files that it will use:\n",
    " - `in1`: The file containing the downsampled read_1 reads (from the `dfastq` folder)\n",
    " - `in2`: The file containing the downsampled read_2 reads (from the `dfastq` folder)\n",
    " \n",
    "It also has three output files that it will generate; we will save all of these in your `Lab7` folder.\n",
    " - `out`: The merged reads (combining overlapping read 1 and read 2 reads into a single read)-should be saved in your `Lab7` folder\n",
    " - `outu1`: The unmerged read 1 reads (ie the read 1 reads that didn't overlap with their paired end and remain the same) -should be saved in your `Lab7` folder\n",
    " - `outu2`: The unmerged read 2 reads (ie the read 2 reads that didn't overlap with their paired end and remain the same) - should also be saved in your `Lab7` folder\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462de1a-05e6-4c39-bb8a-e5337f0856de",
   "metadata": {},
   "source": [
    "**Question** What does the program need 2 input files and 3 output files?\n",
    "\n",
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f9c898-ba77-4eea-8f84-93b71a32d00b",
   "metadata": {},
   "source": [
    "Before we run the program we are going to set up all of our file names as variables. Just like careful pipetting is critical to the success of a wet lab, proper file naming is going to be critical in this and future lab! We will assign each file name as a variable. `Samplename `refers to the ZP_# name of your pool. Please do not actually name your file \"samplename\"! Your input files already have names, so you will just need to make up names for your output files\n",
    " \n",
    "How to name your files to save them in your Lab7 folder: (replace `samplename` with your ZP_ sample number)\n",
    " - `out`: `samplename.merged.fq`\n",
    " - `out1`: `samplename_1.unmerged.fq`\n",
    " - `out2`: `samplename_2.unmerged.fq`\n",
    " \n",
    "Set up the names of all your files in the code block below. Because different files are in in different folders, you'll need to supply the full path (the location with all the folders) for each input and output file. **It is essential that you save the output files in your Lab7 folder-you'll have issues downstream if they aren't in the right place!** Don't forget you can use `${WD}` as a shortcut to this location! Once you have all the file names entered, copy this code to the terminal to save the variable names. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8face17f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in1=\n",
    "in2=\n",
    "out=\n",
    "out1=\n",
    "out2=\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c0b192",
   "metadata": {},
   "source": [
    "Copy and paste all 5 lines above into terminal to save all the file names as variables. You may have to hit enter one extra time to make all 5 lines run.\n",
    "\n",
    "Then run the code below to do the merging; if you did everything correct above, you shouldn't need to change anything. Note that we are using the variable names that we set up above to tell the computer which files to use for the input and output. If we had to type all of those file names, this would be a very long bit of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ddfac-330c-409d-93fd-342c5ae65308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bbmerge.sh \\\n",
    "    in1=${in1} \\\n",
    "    in2=${in2} \\\n",
    "    out=${out} \\\n",
    "    outu1=${out1} \\\n",
    "    outu2=${out2} \\\n",
    "    strict=t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fa521b-9bbb-471a-b7a2-e53e24fc1f75",
   "metadata": {},
   "source": [
    "**Question: The total number of merged and unmerged reads should add up to our original number of reads (which you calculated in step 6. Use the appropriate command from Table 2 to count the number of lines in your merged file and your unmerged read 1 file. Report all the numbers here. Do the numbers make sense?**\n",
    "\n",
    "**Answer here**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4ff3a0-7199-46c3-9b4e-98d311980d8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 8. Mapping the reads\n",
    "\n",
    "Now it's time to map or align your fastq files to the reference genome. The program we will use is called `bwa`, which stands for Burrows-Wheeler aligner; named after the two people who invented the algorithm that it uses. Recall that when we mapped reads by hand, you scanned the DNA sequence of the reference genome looking for similarities between it and your sequencing read. This is essentially what the `bwa` program does, but it has to scan all ~150,000,000 bases of our reference genome and potentially deal with frequent mismatches. \n",
    "\n",
    "Each person will run BWA twice: once on their merged reads, and once on their unmerged (still paired-end reads). \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46115091-a2a1-4101-8e0e-b7991f4999e2",
   "metadata": {},
   "source": [
    "\n",
    "**Question: how do you think the mapping algorithm works differently when it is using single reads (the merged reads) vs paired reads (the read_1 and read_2 files)? Remember the physical relationship between paired end reads.**\n",
    "\n",
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df2661-3f8a-4ddd-8c72-edba87bccaf1",
   "metadata": {},
   "source": [
    "The overall syntax of how we run the program is\n",
    "\n",
    "`bwa mem -M -t 3 <reference_genome> <fastq_file> <(fastq_file_2)> > <output_file.sam>`\n",
    "\n",
    " - `mem` is the specific algorithm the computer uses to map the reads to the reference genome\n",
    " - `-M` is an option that makes the output files compatible with a program we will use in the future\n",
    " - `-t 3` tells the computer to use 3 computing cores (the number you have reserved from the previous step\n",
    " - `reference_genome` is the fasta file that contains our reference genome file (we looked at it last week)\n",
    " - `fastq_file` is the reads that you want to map: these will be the outputs from our merging steps!\n",
    " - `fastq_file_2` is the optional paired end data for what you want to map (not applicable for the merged reads)\n",
    " - `>` means \"save the output to the file name after this symbol\". This is a very common way to save files in Linux\n",
    " - `output_file` is the name of the file we will save the mapping data to. It has to end in \".sam\". Ideally it will have the same name as the input file but end in .sam instead of .fastq\n",
    " \n",
    " \n",
    "Below you will need to set up the code to run the merged and paired end files through bwa. The lines that have a # in front of them are notes and will not be read by Linux. The lines without a # are the actual code. The second step is going to take 10-15 minutes to run most likely, so you can move on and start working on the next section once your code is running, then come back to answer the questions below about the output of bwa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5543c076-8934-4687-aa80-ae3943eb2ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the code below to map the merged reads. \n",
    "\n",
    "#path to the file with the reference genome (the fasta file we looked at last week in `~/shared_perickso`)\n",
    "ref=\n",
    "\n",
    "#file you want to save to. should be saved in your `Lab7 folder` and named `ZP_#_merged.sam` (replace the # with your sample #)\n",
    "merged_mapped=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6aac7a-c375-4b1e-b189-95deaf032a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#below is the code that will actually run the mapping for the merged reads, once you've run the above\n",
    "bwa mem -M -t 3 $ref ${out} > $merged_mapped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f415153-4aa9-40e3-aa16-3434e30a7f1b",
   "metadata": {},
   "source": [
    "Most of our reads are unmerged, so this next step is going to take longer, after you start the `bwa  mem` step you can proceed to the questions below while the code is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4516401-181c-4973-9a3c-c10b3d44f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now set up the code below to map the unmerged reads--the ones that are still separate as read 1 and read 2\n",
    "\n",
    "#file that you want to save to. shouldbe saved in your `Lab7` folder named `ZP_#_merged.sam` (replace the # with your sample number)\n",
    "unmerged_mapped="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7759eda8-f85a-4ba4-8fa2-04ca791f7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this code to run the mapping for the unmerged reads--you can expect this to take 10-15 minutes. \n",
    "bwa mem -M -t 3 $ref ${out1} ${out2} > $unmerged_mapped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0506e722-1f0d-46de-bd7d-3ace282374a4",
   "metadata": {},
   "source": [
    "**Question: While your code is running, look at your output .sam file for the merged reads which should be done (hint: use `less -S <filename>` to look at them in an orderly way that uses tabs to organize the columns). What key information does the sam file appear to contain?**\n",
    "\n",
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b2a048-dda0-4376-8115-547e3a89f19b",
   "metadata": {},
   "source": [
    "**Question: While you are still waiting, read about the sam file format here: https://en.wikipedia.org/wiki/SAM_(file_format). What column will tell you where in the genome the sequence was aligned to?**\n",
    "\n",
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9183ac4a-4b7f-4499-a707-f02cd464b46a",
   "metadata": {},
   "source": [
    "**Question What column would be important if you wanted to identify reads that were a poor match to the reference genome?**\n",
    "\n",
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec46437",
   "metadata": {
    "tags": []
   },
   "source": [
    "Look at the output that printed to your screen after running each job:\n",
    "\n",
    "**Question: how long did it take to run the two jobs?** \n",
    "\n",
    "**Answer here**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf933e-9711-49f5-93cc-612655876482",
   "metadata": {},
   "source": [
    "**Question: these reads where downsampled to 0.5% of their original read depth; how long would it have taken to run the whole file this way?**\n",
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d13f5f6-a504-4da2-9754-52fbce181925",
   "metadata": {},
   "source": [
    "**Question: look at your output .sam files (hint: use `less -S <filename>` to look at them in an orderly way that uses tabs to organize the columns). What key information does the sam file appear to contain?**\n",
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb09df5-38a5-4c14-8041-99996993c3f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Question: these reads where downsampled to 0.5% of their original read depth; how long would it have taken to run the whole file this way? (this is why I have to process the full dataset behind the scenes for you!)**\n",
    "\n",
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d32161",
   "metadata": {},
   "source": [
    "## 9. Sorting, filtering, and converting to a bam file\n",
    "We are so close to being done! We've mapped our reads to the genome, but we need to sort them and save them as a new tuype of file. Sorting puts all the mapped reads in order along the reference genome. Sorting is required for many downsteram steps. This step will also convert our sam files into a binary format file called a bam file. The information remains the same, but it is compressed and easier for the computer to work with. However, once it is in binary format, it is no longer human-readable, so it will just look like random characters if you tried to look at it with the `less` command.\n",
    "\n",
    "This is also the step where we can remove poorly mapped reads by setting a quality filter. The `-q 40` option below means that we will remove anything with a mapping quality lower than 40. This is the first of many important filtering steps that will happen! \n",
    "\n",
    "You will need to repeat the sorting and filtering steps for both your merged and unmerged sam files. \n",
    "\n",
    "Your input file will be the output from the mapping step above. oOu will need to make up a new filename for the output file. You should include the word \"sorted\" in your sorted file name, so it will be something like `ZP_#_sorted.bam`. It's critical to have the `.bam` in the output file name so that the program saves the data in the correct format. Make sure that everything still gets saved in your Lab7 folder! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66626c7-dc01-41f0-920d-5809a456e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#provide the output named of your merged, sorted bam file using the guidelines above\n",
    "merged_sorted=\n",
    "\n",
    "#then run this command:\n",
    "samtools sort -b -q 40 --threads 3  $merged_mapped> $merged_sorted\n",
    "\n",
    "#now provide an output name for the unmerged, sorted bam\n",
    "unmerged_sorted=\n",
    "\n",
    "#then run this command:\n",
    "samtools view -b -q 40 --threads 3  $unmerged_mapped > $unmerged_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e2e3e8",
   "metadata": {},
   "source": [
    "**Question: Take a look at one of the bam files you just made with `less`. What does it look like inside?**\n",
    "\n",
    "**Answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8b56c1",
   "metadata": {},
   "source": [
    "## 10. Combine files\n",
    "Now that our bam files are created and sorted, we can combine them into a final bam file containing all of our mapped reads (from the merged and unmerged). The syntax for this command is different; instead of using a > to tell the program where to save the file, the name of the **output** file is the first argument after the command\n",
    "\n",
    "`samtools merge <output_file> <input_file_1> <input_file_2>`\n",
    "\n",
    "**Your `output_file` should be named `ZP_#_final.bam` and saved in your Lab7 folder (`${WD}`--I'll be checking to make sure this file is here!** \n",
    "\n",
    "This is your final little check to see if you understand how some of the code worked above. Use the example above to create a line of code below that will combine your bam files that you made in step 9 into a final bam file named and located as described above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35422319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the syntax explanation above to write your command below,  then run it. Remember that your input files are the sorted files you created above! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b64f5b",
   "metadata": {},
   "source": [
    "**Final assignment: To check your understanding of what we did today, write a 3-4 sentence \"Methods\" section outlining what we did with our raw data to merge, map, filter and sort it. You do not need to include specifics like the names of files or folders, but you should name each program we used and say what it did. If time is running short, you can complete this part outside of the lab period and turn it in as soon as you are able.**\n",
    "\n",
    "**Paragraph here*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5dcdfd-d3dc-466f-806d-8f5e1126f0d4",
   "metadata": {},
   "source": [
    "When you are done, hit File> Print. Then print the resulting window to a PDF and upload to Blackboard for Lab 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2ba6f-cbb9-49a1-8166-32bd8040a947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
